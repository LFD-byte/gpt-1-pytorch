Namespace(attn_dropout=0.1, batch_size=16, cached_label_dict='cached_label_dict.json', distributed=True, do_eval=True, embd_dropout=0.1, epochs=100, ffn_hidden=3072, finetune=True, hidden=768, local_rank=1, lr=1.5e-05, max_seq_len=384, n_attn_heads=12, n_layers=12, n_workers=6, no_cuda=False, output_model_prefix='model', pretrain=False, pretrained_model='.model/model.ep22', pretrained_sp_model='wiki103-25000.model', resid_dropout=0.1, test_corpus='.data/aclImdb/imdb.test', train_corpus='.data/aclImdb/imdb.train', vocab_file='wiki103-25000.vocab')
Namespace(attn_dropout=0.1, batch_size=16, cached_label_dict='cached_label_dict.json', distributed=True, do_eval=True, embd_dropout=0.1, epochs=100, ffn_hidden=3072, finetune=True, hidden=768, local_rank=0, lr=1.5e-05, max_seq_len=384, n_attn_heads=12, n_layers=12, n_workers=6, no_cuda=False, output_model_prefix='model', pretrain=False, pretrained_model='.model/model.ep22', pretrained_sp_model='wiki103-25000.model', resid_dropout=0.1, test_corpus='.data/aclImdb/imdb.test', train_corpus='.data/aclImdb/imdb.train', vocab_file='wiki103-25000.vocab')
Loading features from cached file cached_features_finetune_train_384
Loading features from cached file cached_features_finetune_train_384
Loading features from cached file cached_features_finetune_test_384
Loading features from cached file cached_features_finetune_test_384
Iteration 78 (78/391)   Loss: 2.7504 Acc: 50.5%
Iteration 156 (156/391) Loss: 2.5440 Acc: 52.2%
Iteration 234 (234/391) Loss: 2.4165 Acc: 54.4%
Iteration 312 (312/391) Loss: 2.3180 Acc: 56.8%
Iteration 390 (390/391) Loss: 2.2370 Acc: 58.9%
Train Epoch 1 [rank: 0] >       Loss: 2.2313 / Acc: 58.7%
Function Time: train    >       9 min 24 sec
Train Epoch 1 [rank: 1] >       Loss: 2.2256 / Acc: 60.3%
Eval Epoch 1 [rank: 1]  >       Loss: 1.7514 / Acc: 76.1%
Eval Epoch 1 [rank: 0]  >       Loss: 1.7543 / Acc: 76.6%
Iteration 78 (78/391)   Loss: 1.8530 Acc: 74.9%
Iteration 156 (156/391) Loss: 1.7942 Acc: 76.7%
Iteration 234 (234/391) Loss: 1.7546 Acc: 77.9%
Iteration 312 (312/391) Loss: 1.7342 Acc: 78.6%
Iteration 390 (390/391) Loss: 1.7090 Acc: 79.6%
Train Epoch 2 [rank: 0] >       Loss: 1.7046 / Acc: 79.4%
Function Time: train    >       9 min 12 sec
Train Epoch 2 [rank: 1] >       Loss: 1.6878 / Acc: 79.5%
Eval Epoch 2 [rank: 1]  >       Loss: 1.5613 / Acc: 83.3%
Eval Epoch 2 [rank: 0]  >       Loss: 1.5719 / Acc: 83.9%
Iteration 78 (78/391)   Loss: 1.6544 Acc: 83.2%
Iteration 156 (156/391) Loss: 1.6036 Acc: 84.4%
Iteration 234 (234/391) Loss: 1.5798 Acc: 84.8%
Iteration 312 (312/391) Loss: 1.5688 Acc: 85.1%
Iteration 390 (390/391) Loss: 1.5551 Acc: 85.4%
Train Epoch 3 [rank: 0] >       Loss: 1.5511 / Acc: 85.2%
Function Time: train    >       9 min 1 sec
Train Epoch 3 [rank: 1] >       Loss: 1.5495 / Acc: 84.8%
Eval Epoch 3 [rank: 1]  >       Loss: 1.4867 / Acc: 85.6%
Eval Epoch 3 [rank: 0]  >       Loss: 1.4942 / Acc: 86.0%
Iteration 78 (78/391)   Loss: 1.5765 Acc: 85.3%
Iteration 156 (156/391) Loss: 1.5205 Acc: 86.7%
Iteration 234 (234/391) Loss: 1.5028 Acc: 87.1%
Iteration 312 (312/391) Loss: 1.4954 Acc: 87.3%
Iteration 390 (390/391) Loss: 1.4799 Acc: 87.9%
Train Epoch 4 [rank: 0] >       Loss: 1.4761 / Acc: 87.6%
Function Time: train    >       9 min 13 sec
Train Epoch 4 [rank: 1] >       Loss: 1.4723 / Acc: 87.3%
Eval Epoch 4 [rank: 1]  >       Loss: 1.4996 / Acc: 85.4%
Eval Epoch 4 [rank: 0]  >       Loss: 1.5131 / Acc: 85.9%
Iteration 78 (78/391)   Loss: 1.4996 Acc: 87.9%
Iteration 156 (156/391) Loss: 1.4539 Acc: 89.1%
Iteration 234 (234/391) Loss: 1.4446 Acc: 89.1%
Iteration 312 (312/391) Loss: 1.4430 Acc: 88.9%
Iteration 390 (390/391) Loss: 1.4287 Acc: 89.6%
Train Epoch 5 [rank: 0] >       Loss: 1.4250 / Acc: 89.3%
Function Time: train    >       9 min 13 sec
Train Epoch 5 [rank: 1] >       Loss: 1.4152 / Acc: 89.7%
Eval Epoch 5 [rank: 1]  >       Loss: 1.4723 / Acc: 86.7%
Eval Epoch 5 [rank: 0]  >       Loss: 1.4804 / Acc: 87.1%
Iteration 78 (78/391)   Loss: 1.4671 Acc: 89.7%
Iteration 156 (156/391) Loss: 1.4282 Acc: 89.7%
Iteration 234 (234/391) Loss: 1.4083 Acc: 90.2%
Iteration 312 (312/391) Loss: 1.4010 Acc: 90.4%
Iteration 390 (390/391) Loss: 1.3885 Acc: 90.8%
Train Epoch 6 [rank: 0] >       Loss: 1.3850 / Acc: 90.6%
Function Time: train    >       9 min 10 sec
Train Epoch 6 [rank: 1] >       Loss: 1.3809 / Acc: 91.0%
Eval Epoch 6 [rank: 1]  >       Loss: 1.5058 / Acc: 86.3%
Eval Epoch 6 [rank: 0]  >       Loss: 1.5079 / Acc: 86.5%
Iteration 78 (78/391)   Loss: 1.4461 Acc: 90.1%
Iteration 156 (156/391) Loss: 1.3932 Acc: 91.6%
Iteration 234 (234/391) Loss: 1.3863 Acc: 91.5%
Iteration 312 (312/391) Loss: 1.3746 Acc: 91.7%
Iteration 390 (390/391) Loss: 1.3611 Acc: 92.2%
Train Epoch 7 [rank: 0] >       Loss: 1.3576 / Acc: 91.9%
Function Time: train    >       9 min 11 sec
Train Epoch 7 [rank: 1] >       Loss: 1.3452 / Acc: 92.3%
Eval Epoch 7 [rank: 1]  >       Loss: 1.5385 / Acc: 86.7%
Eval Epoch 7 [rank: 0]  >       Loss: 1.5321 / Acc: 87.0%
Iteration 78 (78/391)   Loss: 1.4155 Acc: 91.2%
Iteration 156 (156/391) Loss: 1.3768 Acc: 91.9%
Iteration 234 (234/391) Loss: 1.3556 Acc: 92.3%
Iteration 312 (312/391) Loss: 1.3457 Acc: 92.6%
Iteration 390 (390/391) Loss: 1.3338 Acc: 93.0%
Train Epoch 8 [rank: 0] >       Loss: 1.3304 / Acc: 92.8%
Function Time: train    >       9 min 11 sec
Train Epoch 8 [rank: 1] >       Loss: 1.3303 / Acc: 92.7%
Eval Epoch 8 [rank: 1]  >       Loss: 1.5564 / Acc: 86.6%
Eval Epoch 8 [rank: 0]  >       Loss: 1.5480 / Acc: 86.8%